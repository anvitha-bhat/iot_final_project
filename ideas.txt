dataset:ASVspoof 2017 dataset https://datashare.is.ed.ac.uk/handle/10283/3055
1. extract features of phonemes
2. void
3. other possible features (not implemented): breath(60 Hz and 600 Hz, 10-20 breaths per min)/background noise before saying password and after 
(when there is no phonemes and low power)


At the same time, independently:
3. doppler
4.check background noice consistency during/outside speech





phonetic segmentation:

The paper uses microphone arrays to compute DoA. However, in real-world settings, computers usually
do not have more than one microphones. But security for computer voice systems is also
very important. For example, voice assistance, zoom meeting. Some other devices also do not 
have microphone arrays. Therefore, we need to develop a method that reqires only one
microphone recording. We need to keep the reqiurement of computation power low at the 
same time. So, instead of using full spectrogram or full dignal to train convolutional/
recurrent/residual NNs, We propose to extract light-weight features and use 2-layer linear
NNs. We conjecture that each phoneme have unique features that can help the system identify
whether it's real or not. So we extract frames of each phoneme, and obtain MFCC + filterbank 
energy features. We average these values for each type of phoneme so that the dimension
is small. We also use CPA to reduce dimension of extracted features. We only have 264 dimensions
for each sample. The raw signal have more than 45000 data points and spectrogram are also
very large in comparison.

We restricted dictionary size to improve accuracy. This is also a good choice in real-world 
settings, because voice passwords are often generated following a specific rule. Then, we can 
add only those potential words to our dictionary.
   S01: 'My voice is my password'
    S02: 'OK Google'
    S03: 'Only lawyers love millionaires'
    S04: 'Artificial intelligence is for real'
    S05: 'Birthday parties have cupcakes and ice cream'
    S06: 'Actions speak louder than words'
    S07: 'There is no such thing as a free lunch'
    S08: 'A watched pot never boils'
    S09: 'Jealousy has twenty-twenty vision'
    S10: 'Necessity is the mother of invention'

install SRILM for building language model to improve accuracy of phonetic segmentation
https://okapiframework.org/wiki/index.php/SRILM_Installation_and_Running_Tutorial
Run SRILM to create language model: https://cmusphinx.github.io/wiki/phonemerecognition/
ngram-count -text PasswordPhonemes.txt -lm PhoneticLanguageModel.lm
./ngram-count -text [corpus] -lm [output_language_model] -order 3 -write [output_ngram_file_path]
But result is not idea.


feature extraction through MFCC + filterbank energy + Void 
https://python-speech-features.readthedocs.io/en/latest/

void_feature_label_train.npy obtained from https://github.com/chislab/void-voice-liveness-detection/blob/master/train_svm.py

ASVspoof 2017 training dataset is splitted 30:70 for training and test. The test part is not used during training.

Train overparameterized NNs to classify samples